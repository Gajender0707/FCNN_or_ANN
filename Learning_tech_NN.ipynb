{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NuVUqPsHGR8f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pMKW9dDKGf7Z"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Data_for_Regression_Simple_Practice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uM0l8iCYGjzJ",
    "outputId": "f4f8c6db-3bd3-461c-c1d9-1fc091640b9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x     y\n",
       "0  3.0  20.6\n",
       "1  4.0  24.8\n",
       "2  5.0  29.0\n",
       "3  1.0  12.2\n",
       "4  2.0  16.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Nn05NwrGlvM",
    "outputId": "f03ab8bf-47ed-46d2-b6fd-eb84ea783c7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RTBd22yfN6KF"
   },
   "outputs": [],
   "source": [
    "x=data.x\n",
    "y=data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5iw8tDgN6Ne"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcYTONsVGr0T",
    "outputId": "f9e3ecd7-cd93-46ee-fb30-c7e72242968d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gEB2LHUOIZqH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrdMNQYQIZtm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "olVSZEiBGsje"
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=1, activation='tanh'))\n",
    "    model.add(Dense(5,activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    opt=Adagrad(learning_rate=0.001, initial_accumulator_value=0.1, epsilon=1e-07,\n",
    "                name='Adagrad')\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fxWGL9l6KlsD"
   },
   "outputs": [],
   "source": [
    "model=baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim*layer1*layer2    #this will show the total parameter in the summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*10*5*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwG14RKOMxi1",
    "outputId": "1f532d17-a630-4a72-a77d-b2c0b7f2dc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 3ms/step - loss: 1467.1658\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1458.5660\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1452.8538\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1448.2098\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1444.2145\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1440.6373\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1437.3638\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1434.3204\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1431.4805\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1428.7902\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1426.2316\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1423.7870\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1421.4424\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1419.1804\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1417.0026\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1414.8987\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1412.8569\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1410.8741\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1408.9513\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1407.0698\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1405.2458\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1403.4611\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1401.7141\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1400.0060\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1398.3341\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1396.6987\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1395.0905\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1393.5145\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1391.9604\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1390.4404\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1388.9423\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1387.4669\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1386.0183\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1384.5861\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1383.1766\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1381.7880\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1380.4163\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1379.0624\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1377.7244\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1376.4037\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1375.1000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1373.8086\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1372.5326\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1371.2715\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1370.0226\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1368.7897\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1367.5657\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1366.3582\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1365.1610\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1363.9734\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1362.8003\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1361.6333\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1360.4824\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1359.3389\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1358.2025\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1357.0775\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1355.9633\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1354.8544\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1353.7548\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1352.6638\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1351.5818\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1350.5090\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1349.4398\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1348.3781\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1347.3285\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1346.2839\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1345.2423\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1344.2114\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1343.1871\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1342.1707\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1341.1548\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1340.1522\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1339.1509\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1338.1559\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1337.1674\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1336.1858\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1335.2089\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1334.2355\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1333.2703\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1332.3083\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1331.3530\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1330.4028\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1329.4591\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1328.5160\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1327.5801\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1326.6525\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1325.7263\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1324.8057\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1323.8882\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1322.9784\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1322.0734\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1321.1689\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1320.2719\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1319.3787\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1318.4922\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1317.6094\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1316.7290\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1315.8550\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1314.9847\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1314.1190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d223e850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=2,verbose=1,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PEaTGkfMN4JO"
   },
   "outputs": [],
   "source": [
    "def Neural_network():\n",
    "    model=Sequential()   #this is the tensorflow libarary which is help in the run the all layer in a squence .....\n",
    "    model.add(Dense(20,input_dim=1,activation=\"tanh\"))   #this is the first layer ,Dense is the number of neurons,input_dim is the \n",
    "    #number of Features in the datasets,activation is the non-linearity in the model\n",
    "    model.add(Dense(10,activation=\"tanh\"))   # this is the second layer in which number of neurons are 10 and non-linearity is tanh\n",
    "    model.add(Dense(5,activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    opt=Adagrad(learning_rate=0.001, initial_accumulator_value=0.1, epsilon=1e-07)  #this is the optimizer in the which see the \n",
    "    #learning technique\n",
    "    model.compile(optimizer=opt,loss=\"mean_squared_error\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1366.4775\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1349.5422\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1338.3140\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1329.4478\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1322.0814\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1315.7498\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1310.2339\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1305.3167\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1300.8821\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1296.8654\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1293.1667\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1289.7635\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1286.5986\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1283.6511\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1280.8875\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1278.2859\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1275.8378\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1273.5117\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1271.3091\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1269.2064\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1267.2045\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1265.2889\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1263.4565\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1261.6942\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1531.65 - 0s 2ms/step - loss: 1259.9988\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1258.3733\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1256.8088\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1255.2969\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1253.8374\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1252.4242\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1251.0619\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1249.7393\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1248.4567\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1247.2170\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1246.0088\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1244.8374\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1243.6978\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1242.5913\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1241.5120\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1240.4591\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1239.4348\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1238.4352\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1237.4636\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1236.5131\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1235.5804\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1234.6736\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1233.7876\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1232.9188\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1232.0690\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1231.2374\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1230.4232\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1229.6268\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1228.8451\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1228.0790\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1227.3276\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1226.5905\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1225.8676\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1225.1575\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1224.4606\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1223.7762\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1223.1039\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1222.4434\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1221.7942\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1221.1559\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1220.5278\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1219.9099\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1219.3030\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1218.7050\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1218.1165\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1217.5372\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1216.9648\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1216.4034\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1215.8513\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1215.3047\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1214.7668\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1214.2363\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1213.7136\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1213.1981\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1212.6898\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1212.1874\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1211.6929\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1211.2043\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1210.7227\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1210.2465\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1209.7769\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1209.3125\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1208.8550\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1208.4020\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1207.9543\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1207.5142\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1207.0774\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1206.6464\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1206.2192\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1205.7987\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1205.3824\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1204.9707\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1204.5630\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1204.1599\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1203.7625\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1203.3682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d33f7b50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,verbose=1,epochs=100,batch_size=2)  #batch_size is the number of batch of total datasets i.e  x.shape=32 \n",
    "#then if the batch_size=2 then it will divide in the 2 parts of 16,16\n",
    "#epochs is the number of loops in the our model\n",
    "#verbose  show the running status of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>17.3722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>19.5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>23.9704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2   Target\n",
       "0  1.0  5.1  15.1728\n",
       "1  2.0  5.4  17.3722\n",
       "2  3.0  5.7  19.5716\n",
       "3  4.0  6.0  21.7710\n",
       "4  5.0  6.3  23.9704"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data1.Target\n",
    "x=data1.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>6.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4000</td>\n",
       "      <td>6.12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.4000</td>\n",
       "      <td>6.42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>6.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.3000</td>\n",
       "      <td>6.69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.4500</td>\n",
       "      <td>5.53500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>6.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.9000</td>\n",
       "      <td>5.67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.4000</td>\n",
       "      <td>5.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.0000</td>\n",
       "      <td>8.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.2000</td>\n",
       "      <td>8.16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.9000</td>\n",
       "      <td>5.67000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.8000</td>\n",
       "      <td>7.44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.6700</td>\n",
       "      <td>7.40100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.5600</td>\n",
       "      <td>6.16800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.5000</td>\n",
       "      <td>6.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.8000</td>\n",
       "      <td>7.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.8000</td>\n",
       "      <td>7.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.4500</td>\n",
       "      <td>5.83500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.6000</td>\n",
       "      <td>6.48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.8000</td>\n",
       "      <td>7.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>5.09625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.4000</td>\n",
       "      <td>5.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.6000</td>\n",
       "      <td>6.48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>23.0000</td>\n",
       "      <td>11.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>7.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>9.0000</td>\n",
       "      <td>7.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>12.9800</td>\n",
       "      <td>8.69400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.2300</td>\n",
       "      <td>7.86900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.4500</td>\n",
       "      <td>5.83500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6.7554</td>\n",
       "      <td>6.82662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>12.0000</td>\n",
       "      <td>8.40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2\n",
       "0    1.0000   5.10000\n",
       "1    2.0000   5.40000\n",
       "2    3.0000   5.70000\n",
       "3    4.0000   6.00000\n",
       "4    5.0000   6.30000\n",
       "5    6.0000   6.60000\n",
       "6    2.0000   5.40000\n",
       "7    3.0000   5.70000\n",
       "8    4.4000   6.12000\n",
       "9    5.0000   6.30000\n",
       "10   3.0000   5.70000\n",
       "11   5.4000   6.42000\n",
       "12   6.0000   6.60000\n",
       "13   6.3000   6.69000\n",
       "14   4.0000   6.00000\n",
       "15   5.0000   6.30000\n",
       "16   2.4500   5.53500\n",
       "17   5.0000   6.30000\n",
       "18   6.0000   6.60000\n",
       "19   2.9000   5.67000\n",
       "20   3.4000   5.82000\n",
       "21   5.0000   6.30000\n",
       "22   3.0000   5.70000\n",
       "23  12.0000   8.40000\n",
       "24  11.2000   8.16000\n",
       "25   2.9000   5.67000\n",
       "26   8.8000   7.44000\n",
       "27   8.6700   7.40100\n",
       "28   4.5600   6.16800\n",
       "29   5.0000   6.30000\n",
       "30   6.5000   6.75000\n",
       "31   4.0000   6.00000\n",
       "32   7.8000   7.14000\n",
       "33   9.8000   7.74000\n",
       "34   2.0000   5.40000\n",
       "35   3.4500   5.83500\n",
       "36   5.6000   6.48000\n",
       "37   7.8000   7.14000\n",
       "38   0.9875   5.09625\n",
       "39   3.4000   5.82000\n",
       "40   5.6000   6.48000\n",
       "41  23.0000  11.70000\n",
       "42  10.0000   7.80000\n",
       "43   9.0000   7.50000\n",
       "44  12.9800   8.69400\n",
       "45  10.2300   7.86900\n",
       "46   2.0000   5.40000\n",
       "47   3.4500   5.83500\n",
       "48   6.7554   6.82662\n",
       "49  12.0000   8.40000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,input_dim=2,activation=\"tanh\"))\n",
    "    model.add(Dense(20,activation=\"tanh\"))\n",
    "    model.add(Dense(10,activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    opt=Adagrad(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt,loss=\"mean_squared_error\")    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 581.4135\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 499.6608\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 477.0436\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 461.8082\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 449.8575\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 439.7894\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 430.9640\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 423.0736\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 415.9132\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 409.3283\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 403.2174\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 397.4975\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 392.1302\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 387.0529\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 382.2358\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 377.6458\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 373.2576\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 369.0566\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 365.0190\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 361.1359\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 357.3972\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 353.7854\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 350.2907\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 346.9046\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 343.6261\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 340.4427\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 337.3457\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 334.3351\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 331.4079\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 328.5566\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 325.7747\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 323.0604\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 320.4114\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 317.8260\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 315.2933\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 312.8227\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 310.4016\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 308.0344\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 305.7148\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 303.4415\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 301.2152\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 299.0319\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 296.8880\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 294.7862\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 292.7223\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 290.6992\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 288.7078\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 286.7536\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 284.8304\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 282.9432\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 281.0890\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 279.2614\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 277.4671\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 275.6988\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 273.9599\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 272.2498\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 270.5630\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 268.9025\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 267.2700\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 265.6564\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 264.0705\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 262.5034\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 260.9627\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 259.4418\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 257.9448\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 256.4650\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 255.0085\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 253.5681\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 252.1480\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 250.7489\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 249.3676\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 248.0031\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 246.6575\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 245.3263\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 244.0143\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 242.7164\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 241.4374\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 240.1744\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 238.9247\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 237.6900\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 236.4707\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 235.2651\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 234.0760\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 232.8972\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 231.7343\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 230.5836\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 229.4486\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 228.3255\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 227.2112\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 226.1149\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 225.0266\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 223.9540\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 222.8900\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 221.8381\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 220.7975\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 219.7668\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 218.7486\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 217.7429\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 216.7430\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 215.7575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d34d2b80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,verbose=1,batch_size=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model2():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,activation=\"tanh\",input_dim=2))\n",
    "    model.add(Dense(20,activation=\"tanh\"))\n",
    "    model.add(Dense(10,activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    opt=Adam(learning_rate=0.01)\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 562.4319\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 439.5155\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 347.2630\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 277.1324\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 221.5601\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 178.5907\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 147.0727\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 123.8212\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 107.6145\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 95.1678\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 87.6177\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 82.0723\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 78.4959\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 76.1493\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 74.5858\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 73.9680\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 73.1257\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 72.7997\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 72.6550\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 72.5150\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 72.0859\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 58.8783\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 52.0776\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 51.5860\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 44.2239\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 40.4202\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 36.9513\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 34.3564\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 32.3964\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 30.5951\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 29.2192\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 27.7918\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 26.4699\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 24.5632\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 25.2138\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 25.5956\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 25.0232\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 32.4779\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 26.3400\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 23.9265\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 19.7654\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 18.8075\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 17.7439\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 16.8529\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 16.3179\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 15.8733\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 15.3048\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 14.7961\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.2763\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.9755\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.7065\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.0930\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.8933\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.4943\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.3028\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.0082\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 11.7093\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.6431\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 16.0589\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.7824\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.2064\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.3721\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 11.1296\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.8654\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.9010\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.6710\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.3265\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.7474\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.6162\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.9921\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.7159\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.9544\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.7558\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.2305\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.9289\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.7033\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 16.6719\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.6568\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 31.4268\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 26.0786\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 18.6403\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 20.4840\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 21.5770\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 18.2457\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 15.9489\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.4440\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.6363\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.2818\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.7124\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.4784\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.1217\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.4402\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.2050\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 15.4704\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.8086\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.5334\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.1722\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.5319\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.0377\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d35aaf70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100,batch_size=2,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model3():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,activation=\"tanh\",input_dim=2))\n",
    "    model.add(Dense(20,activation=\"tanh\"))\n",
    "    model.add(Dense(10,activation=\"tanh\"))\n",
    "    model.add(Dense(1))\n",
    "    opt=RMSprop(learning_rate=0.01)\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 499.9732\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 385.6422\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 301.5471\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 235.8298\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 181.0316\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 140.3705\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 113.7747\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 93.1526\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 85.1175\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 70.1392\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 58.6414\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 51.0793\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 43.4063\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 38.5633\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 33.4738\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 30.0899\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 26.3463\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 26.0303\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 23.9686\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 21.3727\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 21.4585\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 19.6089\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 18.7193\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.2217\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.1042\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 16.0263\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.5729\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 15.2795\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.4419\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 14.6478\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.4543\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.9623\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 14.1994\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.0691\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.3575\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.9484\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.8380\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.4174\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 13.1133\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.4186\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.2338\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.7287\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.9907\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.0177\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.4266\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.1645\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.4133\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.4404\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.7825\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.3239\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.2081\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.4367\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 10.9052\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.2614\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.4447\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.9320\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.8853\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 9.5873\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.8381\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.8255\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.4743\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.9766\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.6521\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.4192\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.3113\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.9407\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 8.7881\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.7977\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.2675\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.2519\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.4354\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.5937\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.9969\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.2154\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.0797\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.2781\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.1403\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 15.2213\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.0636\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.2965\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.5358\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7154\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.6205\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.0982\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2204\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4281\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 10.5715\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5681\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7857\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.4249\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7031\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.9585\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2270\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7125\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5891\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7202\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.5345\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.9008\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9864\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.1865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d33c5280>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100,batch_size=2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model4():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,activation=\"relu\",input_dim=2))\n",
    "    model.add(Dense(20,activation=\"relu\"))\n",
    "    model.add(Dense(10,activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    opt=RMSprop(learning_rate=0.01)\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 108.8435\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.3347\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1136\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.6582\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3305\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6276\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.6221\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8551\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.8134\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1833\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.0798\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.8839\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.4821\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.0470\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8571\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3872\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8220\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.8163\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.7833\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.3020\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0779\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8704\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.6616\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.1954\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3438\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7585\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3190\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2665\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.4459\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.1689\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.4383\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.3019\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.7974\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.9027\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.2685\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0821\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.8375\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.0783\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4633\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.3441\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6457A: 0s - loss: 1.645\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7860\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6886\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.0855\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3340\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.6597\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.5620\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4097\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2298\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.8354\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6809\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1486\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1048\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.7927\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2245\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.9329\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2367\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8744\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1323\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.1388\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.7493\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1692\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - ETA: 0s - loss: 3.029 - 0s 2ms/step - loss: 2.9084\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.7650\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1397\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.4704\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2041\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0693\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1360\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.0297\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6417\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5495\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6836\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9451\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9529\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3524\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.0597\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.7173\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6728\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2268\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6905\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8082\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2881\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2978\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2782\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.0647\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.9771\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0229\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8508\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.4240\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.1628\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.1307\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2795\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3115\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0383\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.9554\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.9979\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d4742bb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100,batch_size=2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.140352],\n",
       "       [18.335402],\n",
       "       [20.530449],\n",
       "       [22.7255  ],\n",
       "       [24.92055 ],\n",
       "       [27.115597],\n",
       "       [18.335402],\n",
       "       [20.530449],\n",
       "       [23.60352 ],\n",
       "       [24.92055 ],\n",
       "       [20.530449],\n",
       "       [25.79857 ],\n",
       "       [27.115597],\n",
       "       [27.774115],\n",
       "       [22.7255  ],\n",
       "       [24.92055 ],\n",
       "       [19.323174],\n",
       "       [24.92055 ],\n",
       "       [27.115597],\n",
       "       [20.310946],\n",
       "       [21.40847 ],\n",
       "       [24.92055 ],\n",
       "       [20.530449],\n",
       "       [40.28589 ],\n",
       "       [38.529854],\n",
       "       [20.310946],\n",
       "       [33.261734],\n",
       "       [32.97638 ],\n",
       "       [23.954725],\n",
       "       [24.92055 ],\n",
       "       [28.213121],\n",
       "       [22.7255  ],\n",
       "       [31.066687],\n",
       "       [35.456783],\n",
       "       [18.335402],\n",
       "       [21.51822 ],\n",
       "       [26.237577],\n",
       "       [31.066687],\n",
       "       [16.112915],\n",
       "       [21.40847 ],\n",
       "       [26.237577],\n",
       "       [64.43143 ],\n",
       "       [35.895794],\n",
       "       [33.700745],\n",
       "       [42.43704 ],\n",
       "       [36.400658],\n",
       "       [18.335402],\n",
       "       [21.51822 ],\n",
       "       [28.773737],\n",
       "       [40.28589 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "# r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876020482612856"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Network_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
