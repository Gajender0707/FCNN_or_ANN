{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b786ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72da6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"categorical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c307f668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4424b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d3aa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe47c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "k=LabelEncoder()\n",
    "data[\"Sex\"]= k.fit_transform(data['Sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be82bf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b500bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ba2271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex\n",
       "0       2\n",
       "1       2\n",
       "2       0\n",
       "3       2\n",
       "4       1\n",
       "...   ...\n",
       "4172    0\n",
       "4173    2\n",
       "4174    2\n",
       "4175    0\n",
       "4176    2\n",
       "\n",
       "[4177 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3316269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a15b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab21625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f185664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(\"Sex\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e5e36ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3148f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e6bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac651757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2784, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca06ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebdfe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57b56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,input_dim=8,activation=\"tanh\"))\n",
    "    model.add(Dense(20,activation=\"tanh\"))\n",
    "    model.add(Dense(10,activation=\"tanh\"))\n",
    "    model.add(Dense(5,activation=\"tanh\"))\n",
    "    model.add(Dense(3,activation=\"softmax\"))   #for classification in the last layer number of neuron = number of category in target\n",
    "    #in the last layer non-linearity will also come {  sigmoid,softmax}\n",
    "    opt=Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])  #for classification if binary classification\n",
    "    #loss=\"binary_crossentropy\"  and if multiple classfication loss is =\"categorical_crossentropy\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24e74a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca98f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 1.1082 - accuracy: 0.2780 - val_loss: 1.0664 - val_accuracy: 0.3553\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0581 - accuracy: 0.3797 - val_loss: 1.0607 - val_accuracy: 0.4429\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0627 - accuracy: 0.4443 - val_loss: 1.0170 - val_accuracy: 0.5255\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0209 - accuracy: 0.5126 - val_loss: 0.9881 - val_accuracy: 0.5226\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.9892 - accuracy: 0.5101 - val_loss: 0.9607 - val_accuracy: 0.4903\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.9589 - accuracy: 0.4853 - val_loss: 0.9392 - val_accuracy: 0.5298\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.9430 - accuracy: 0.5273 - val_loss: 0.9091 - val_accuracy: 0.5334\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.9145 - accuracy: 0.5205 - val_loss: 0.9009 - val_accuracy: 0.5190\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.9005 - accuracy: 0.5273 - val_loss: 0.8925 - val_accuracy: 0.5319\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8938 - accuracy: 0.5323 - val_loss: 0.8827 - val_accuracy: 0.5262\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8845 - accuracy: 0.5309 - val_loss: 0.8791 - val_accuracy: 0.5276\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8823 - accuracy: 0.5284 - val_loss: 0.8816 - val_accuracy: 0.5190\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8846 - accuracy: 0.5273 - val_loss: 0.8831 - val_accuracy: 0.5147\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8838 - accuracy: 0.5198 - val_loss: 0.8798 - val_accuracy: 0.5312\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8807 - accuracy: 0.5381 - val_loss: 0.8760 - val_accuracy: 0.5212\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8779 - accuracy: 0.5291 - val_loss: 0.8756 - val_accuracy: 0.5219\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8782 - accuracy: 0.5330 - val_loss: 0.8769 - val_accuracy: 0.5391\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8777 - accuracy: 0.5316 - val_loss: 0.8802 - val_accuracy: 0.5090\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8793 - accuracy: 0.5187 - val_loss: 0.8764 - val_accuracy: 0.5327\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8760 - accuracy: 0.5424 - val_loss: 0.8747 - val_accuracy: 0.5348\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8738 - accuracy: 0.5374 - val_loss: 0.8755 - val_accuracy: 0.5348\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8728 - accuracy: 0.5377 - val_loss: 0.8766 - val_accuracy: 0.5312\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8741 - accuracy: 0.5226 - val_loss: 0.8771 - val_accuracy: 0.5190\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8760 - accuracy: 0.5172 - val_loss: 0.8711 - val_accuracy: 0.5248\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8693 - accuracy: 0.5251 - val_loss: 0.8723 - val_accuracy: 0.5363\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8701 - accuracy: 0.5381 - val_loss: 0.8768 - val_accuracy: 0.5312\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8732 - accuracy: 0.5316 - val_loss: 0.8715 - val_accuracy: 0.5377\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8687 - accuracy: 0.5374 - val_loss: 0.8737 - val_accuracy: 0.5291\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8707 - accuracy: 0.5244 - val_loss: 0.8744 - val_accuracy: 0.5068\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8723 - accuracy: 0.5201 - val_loss: 0.8717 - val_accuracy: 0.5413\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8696 - accuracy: 0.5384 - val_loss: 0.8680 - val_accuracy: 0.5319\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8672 - accuracy: 0.5305 - val_loss: 0.8661 - val_accuracy: 0.5384\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8645 - accuracy: 0.5388 - val_loss: 0.8701 - val_accuracy: 0.5413\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8677 - accuracy: 0.5363 - val_loss: 0.8671 - val_accuracy: 0.5355\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8660 - accuracy: 0.5381 - val_loss: 0.8645 - val_accuracy: 0.5363\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8634 - accuracy: 0.5395 - val_loss: 0.8638 - val_accuracy: 0.5542\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8637 - accuracy: 0.5277 - val_loss: 0.8644 - val_accuracy: 0.5363\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8653 - accuracy: 0.5126 - val_loss: 0.8668 - val_accuracy: 0.5434\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8658 - accuracy: 0.5406 - val_loss: 0.8626 - val_accuracy: 0.5363\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8626 - accuracy: 0.5409 - val_loss: 0.8635 - val_accuracy: 0.5377\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8617 - accuracy: 0.5392 - val_loss: 0.8692 - val_accuracy: 0.5449\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8679 - accuracy: 0.5359 - val_loss: 0.8615 - val_accuracy: 0.5276\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8616 - accuracy: 0.5277 - val_loss: 0.8673 - val_accuracy: 0.5384\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8658 - accuracy: 0.5356 - val_loss: 0.8672 - val_accuracy: 0.5284\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8679 - accuracy: 0.5388 - val_loss: 0.8593 - val_accuracy: 0.5384\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8589 - accuracy: 0.5406 - val_loss: 0.8677 - val_accuracy: 0.5406\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8661 - accuracy: 0.5506 - val_loss: 0.8640 - val_accuracy: 0.5341\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8635 - accuracy: 0.5262 - val_loss: 0.8622 - val_accuracy: 0.5377\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8629 - accuracy: 0.5348 - val_loss: 0.8588 - val_accuracy: 0.5284\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8601 - accuracy: 0.5327 - val_loss: 0.8583 - val_accuracy: 0.5363\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8588 - accuracy: 0.5302 - val_loss: 0.8640 - val_accuracy: 0.5470\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8622 - accuracy: 0.5363 - val_loss: 0.8627 - val_accuracy: 0.5398\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8630 - accuracy: 0.5327 - val_loss: 0.8578 - val_accuracy: 0.5427\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8589 - accuracy: 0.5392 - val_loss: 0.8570 - val_accuracy: 0.5449\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8604 - accuracy: 0.5417 - val_loss: 0.8579 - val_accuracy: 0.5406\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8596 - accuracy: 0.5381 - val_loss: 0.8569 - val_accuracy: 0.5427\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8561 - accuracy: 0.5442 - val_loss: 0.8673 - val_accuracy: 0.5384\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8669 - accuracy: 0.5356 - val_loss: 0.8589 - val_accuracy: 0.5470\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8587 - accuracy: 0.5395 - val_loss: 0.8558 - val_accuracy: 0.5384\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8565 - accuracy: 0.5409 - val_loss: 0.8562 - val_accuracy: 0.5327\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8557 - accuracy: 0.5438 - val_loss: 0.8606 - val_accuracy: 0.5384\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8595 - accuracy: 0.5366 - val_loss: 0.8548 - val_accuracy: 0.5291\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8556 - accuracy: 0.5374 - val_loss: 0.8531 - val_accuracy: 0.5391\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8551 - accuracy: 0.5402 - val_loss: 0.8584 - val_accuracy: 0.5499\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8571 - accuracy: 0.5413 - val_loss: 0.8596 - val_accuracy: 0.5269\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8614 - accuracy: 0.5237 - val_loss: 0.8521 - val_accuracy: 0.5456\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8530 - accuracy: 0.5420 - val_loss: 0.8562 - val_accuracy: 0.5470\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8563 - accuracy: 0.5435 - val_loss: 0.8527 - val_accuracy: 0.5427\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8538 - accuracy: 0.5445 - val_loss: 0.8482 - val_accuracy: 0.5470\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8529 - accuracy: 0.5406 - val_loss: 0.8521 - val_accuracy: 0.5413\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8564 - accuracy: 0.5233 - val_loss: 0.8502 - val_accuracy: 0.5528\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8537 - accuracy: 0.5568 - val_loss: 0.8579 - val_accuracy: 0.5463\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8586 - accuracy: 0.5420 - val_loss: 0.8537 - val_accuracy: 0.5413\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8564 - accuracy: 0.5435 - val_loss: 0.8479 - val_accuracy: 0.5492\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8515 - accuracy: 0.5442 - val_loss: 0.8518 - val_accuracy: 0.5492\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8560 - accuracy: 0.5212 - val_loss: 0.8467 - val_accuracy: 0.5506\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8503 - accuracy: 0.5327 - val_loss: 0.8496 - val_accuracy: 0.5535\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8517 - accuracy: 0.5431 - val_loss: 0.8556 - val_accuracy: 0.5406\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8563 - accuracy: 0.5463 - val_loss: 0.8503 - val_accuracy: 0.5463\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8542 - accuracy: 0.5478 - val_loss: 0.8448 - val_accuracy: 0.5664\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8493 - accuracy: 0.5392 - val_loss: 0.8437 - val_accuracy: 0.5477\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8486 - accuracy: 0.5535 - val_loss: 0.8447 - val_accuracy: 0.5499\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8492 - accuracy: 0.5485 - val_loss: 0.8445 - val_accuracy: 0.5549\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8486 - accuracy: 0.5478 - val_loss: 0.8426 - val_accuracy: 0.5535\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8475 - accuracy: 0.5524 - val_loss: 0.8459 - val_accuracy: 0.5470\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8501 - accuracy: 0.5521 - val_loss: 0.8427 - val_accuracy: 0.5549\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8492 - accuracy: 0.5481 - val_loss: 0.8549 - val_accuracy: 0.5520\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8559 - accuracy: 0.5607 - val_loss: 0.8486 - val_accuracy: 0.5485\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8559 - accuracy: 0.5521 - val_loss: 0.8554 - val_accuracy: 0.5420\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8548 - accuracy: 0.5492 - val_loss: 0.9020 - val_accuracy: 0.5126\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8921 - accuracy: 0.5356 - val_loss: 0.8990 - val_accuracy: 0.5205\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8888 - accuracy: 0.5320 - val_loss: 0.8656 - val_accuracy: 0.5327\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8683 - accuracy: 0.5424 - val_loss: 0.8470 - val_accuracy: 0.5477\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8526 - accuracy: 0.5471 - val_loss: 0.8594 - val_accuracy: 0.5398\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8611 - accuracy: 0.5435 - val_loss: 0.8560 - val_accuracy: 0.5312\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8565 - accuracy: 0.5309 - val_loss: 0.8496 - val_accuracy: 0.5499\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8509 - accuracy: 0.5571 - val_loss: 0.8518 - val_accuracy: 0.5477\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8524 - accuracy: 0.5431 - val_loss: 0.8506 - val_accuracy: 0.5398\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8519 - accuracy: 0.5456 - val_loss: 0.8457 - val_accuracy: 0.5520\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8492 - accuracy: 0.5524 - val_loss: 0.8476 - val_accuracy: 0.5549\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8520 - accuracy: 0.5291 - val_loss: 0.8453 - val_accuracy: 0.5528\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8479 - accuracy: 0.5420 - val_loss: 0.8484 - val_accuracy: 0.5477\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8506 - accuracy: 0.5431 - val_loss: 0.8463 - val_accuracy: 0.5499\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8492 - accuracy: 0.5453 - val_loss: 0.8447 - val_accuracy: 0.5499\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8478 - accuracy: 0.5463 - val_loss: 0.8465 - val_accuracy: 0.5449\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8496 - accuracy: 0.5524 - val_loss: 0.8438 - val_accuracy: 0.5427\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8474 - accuracy: 0.5568 - val_loss: 0.8449 - val_accuracy: 0.5499\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8465 - accuracy: 0.5510 - val_loss: 0.8464 - val_accuracy: 0.5492\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8475 - accuracy: 0.5453 - val_loss: 0.8427 - val_accuracy: 0.5542\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8454 - accuracy: 0.5528 - val_loss: 0.8461 - val_accuracy: 0.5492\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8496 - accuracy: 0.5370 - val_loss: 0.8442 - val_accuracy: 0.5499\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8484 - accuracy: 0.5550 - val_loss: 0.8440 - val_accuracy: 0.5513\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8475 - accuracy: 0.5514 - val_loss: 0.8447 - val_accuracy: 0.5441\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8466 - accuracy: 0.5532 - val_loss: 0.8498 - val_accuracy: 0.5456\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8506 - accuracy: 0.5542 - val_loss: 0.8451 - val_accuracy: 0.5578\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8466 - accuracy: 0.5460 - val_loss: 0.8443 - val_accuracy: 0.5492\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8459 - accuracy: 0.5542 - val_loss: 0.8424 - val_accuracy: 0.5506\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8445 - accuracy: 0.5568 - val_loss: 0.8418 - val_accuracy: 0.5513\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8433 - accuracy: 0.5550 - val_loss: 0.8414 - val_accuracy: 0.5556\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8434 - accuracy: 0.5568 - val_loss: 0.8411 - val_accuracy: 0.5542\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.5539 - val_loss: 0.8427 - val_accuracy: 0.5528\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8433 - accuracy: 0.5499 - val_loss: 0.8418 - val_accuracy: 0.5520\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8432 - accuracy: 0.5589 - val_loss: 0.8403 - val_accuracy: 0.5607\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8434 - accuracy: 0.5636 - val_loss: 0.8481 - val_accuracy: 0.5492\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8482 - accuracy: 0.5546 - val_loss: 0.8429 - val_accuracy: 0.5535\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8449 - accuracy: 0.5539 - val_loss: 0.8666 - val_accuracy: 0.5434\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8599 - accuracy: 0.5514 - val_loss: 0.8578 - val_accuracy: 0.5384\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8584 - accuracy: 0.5262 - val_loss: 0.8510 - val_accuracy: 0.5370\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8529 - accuracy: 0.5535 - val_loss: 0.8409 - val_accuracy: 0.5556\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8429 - accuracy: 0.5517 - val_loss: 0.8389 - val_accuracy: 0.5599\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8406 - accuracy: 0.5578 - val_loss: 0.8380 - val_accuracy: 0.5578\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8419 - accuracy: 0.5672 - val_loss: 0.8374 - val_accuracy: 0.5578\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8418 - accuracy: 0.5614 - val_loss: 0.8404 - val_accuracy: 0.5506\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8429 - accuracy: 0.5593 - val_loss: 0.8389 - val_accuracy: 0.5614\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8415 - accuracy: 0.5614 - val_loss: 0.8371 - val_accuracy: 0.5585\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8411 - accuracy: 0.5632 - val_loss: 0.8368 - val_accuracy: 0.5520\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8395 - accuracy: 0.5704 - val_loss: 0.8407 - val_accuracy: 0.5485\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8415 - accuracy: 0.5611 - val_loss: 0.8472 - val_accuracy: 0.5585\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8477 - accuracy: 0.5690 - val_loss: 0.8431 - val_accuracy: 0.5549\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8433 - accuracy: 0.5485 - val_loss: 0.8405 - val_accuracy: 0.5556\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8429 - accuracy: 0.5665 - val_loss: 0.8385 - val_accuracy: 0.5578\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8398 - accuracy: 0.5639 - val_loss: 0.8465 - val_accuracy: 0.5578\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8461 - accuracy: 0.5665 - val_loss: 0.8375 - val_accuracy: 0.5499\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8390 - accuracy: 0.5625 - val_loss: 0.8380 - val_accuracy: 0.5556\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8380 - accuracy: 0.5639 - val_loss: 0.8458 - val_accuracy: 0.5635\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8434 - accuracy: 0.5636 - val_loss: 0.8548 - val_accuracy: 0.5477\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8520 - accuracy: 0.5560 - val_loss: 0.8409 - val_accuracy: 0.5564\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8395 - accuracy: 0.5665 - val_loss: 0.8531 - val_accuracy: 0.5556\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8457 - accuracy: 0.5546 - val_loss: 0.8530 - val_accuracy: 0.5398\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8582 - accuracy: 0.5208 - val_loss: 0.8355 - val_accuracy: 0.5607\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8367 - accuracy: 0.5675 - val_loss: 0.8517 - val_accuracy: 0.5492\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8487 - accuracy: 0.5481 - val_loss: 0.8354 - val_accuracy: 0.5664\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8396 - accuracy: 0.5582 - val_loss: 0.8384 - val_accuracy: 0.5664\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8410 - accuracy: 0.5571 - val_loss: 0.8392 - val_accuracy: 0.5535\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8397 - accuracy: 0.5585 - val_loss: 0.8572 - val_accuracy: 0.5485\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8534 - accuracy: 0.5481 - val_loss: 0.8462 - val_accuracy: 0.5528\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8461 - accuracy: 0.5618 - val_loss: 0.8513 - val_accuracy: 0.5485\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8524 - accuracy: 0.5395 - val_loss: 0.8401 - val_accuracy: 0.5607\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8424 - accuracy: 0.5517 - val_loss: 0.8391 - val_accuracy: 0.5607\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8399 - accuracy: 0.5528 - val_loss: 0.8366 - val_accuracy: 0.5585\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8376 - accuracy: 0.5618 - val_loss: 0.8340 - val_accuracy: 0.5585\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8373 - accuracy: 0.5726 - val_loss: 0.8339 - val_accuracy: 0.5592\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8368 - accuracy: 0.5700 - val_loss: 0.8434 - val_accuracy: 0.5578\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8433 - accuracy: 0.5679 - val_loss: 0.8419 - val_accuracy: 0.5578\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8406 - accuracy: 0.5564 - val_loss: 0.8476 - val_accuracy: 0.5578\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8471 - accuracy: 0.5600 - val_loss: 0.8371 - val_accuracy: 0.5492\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8379 - accuracy: 0.5639 - val_loss: 0.8360 - val_accuracy: 0.5492\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8367 - accuracy: 0.5779 - val_loss: 0.8359 - val_accuracy: 0.5441\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8364 - accuracy: 0.5708 - val_loss: 0.8359 - val_accuracy: 0.5492\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8364 - accuracy: 0.5740 - val_loss: 0.8363 - val_accuracy: 0.5492\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8362 - accuracy: 0.5643 - val_loss: 0.8452 - val_accuracy: 0.5657\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8438 - accuracy: 0.5629 - val_loss: 0.8410 - val_accuracy: 0.5463\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.8392 - accuracy: 0.5614 - val_loss: 0.8402 - val_accuracy: 0.5564\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8364 - accuracy: 0.5625 - val_loss: 0.8588 - val_accuracy: 0.5441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.8515 - accuracy: 0.5521 - val_loss: 0.8505 - val_accuracy: 0.5535\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8432 - accuracy: 0.5578 - val_loss: 0.8830 - val_accuracy: 0.5384\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8706 - accuracy: 0.5485 - val_loss: 0.8641 - val_accuracy: 0.5578\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8568 - accuracy: 0.5614 - val_loss: 0.8575 - val_accuracy: 0.5485\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8498 - accuracy: 0.5557 - val_loss: 0.8446 - val_accuracy: 0.5607\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8466 - accuracy: 0.5427 - val_loss: 0.8400 - val_accuracy: 0.5564\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8434 - accuracy: 0.5629 - val_loss: 0.8395 - val_accuracy: 0.5513\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8385 - accuracy: 0.5654 - val_loss: 0.8447 - val_accuracy: 0.5621\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8424 - accuracy: 0.5693 - val_loss: 0.8557 - val_accuracy: 0.5463\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8513 - accuracy: 0.5585 - val_loss: 0.8479 - val_accuracy: 0.5628\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8490 - accuracy: 0.5686 - val_loss: 0.8375 - val_accuracy: 0.5578\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8391 - accuracy: 0.5550 - val_loss: 0.8371 - val_accuracy: 0.5549\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8411 - accuracy: 0.5682 - val_loss: 0.8383 - val_accuracy: 0.5578\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8403 - accuracy: 0.5506 - val_loss: 0.8404 - val_accuracy: 0.5564\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8395 - accuracy: 0.5650 - val_loss: 0.8435 - val_accuracy: 0.5564\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8407 - accuracy: 0.5578 - val_loss: 0.8341 - val_accuracy: 0.5635\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8357 - accuracy: 0.5650 - val_loss: 0.8348 - val_accuracy: 0.5642\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8373 - accuracy: 0.5625 - val_loss: 0.8362 - val_accuracy: 0.5607\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8378 - accuracy: 0.5744 - val_loss: 0.8364 - val_accuracy: 0.5642\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8367 - accuracy: 0.5621 - val_loss: 0.8339 - val_accuracy: 0.5614\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8343 - accuracy: 0.5679 - val_loss: 0.8342 - val_accuracy: 0.5564\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8357 - accuracy: 0.5564 - val_loss: 0.8359 - val_accuracy: 0.5607\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8353 - accuracy: 0.5614 - val_loss: 0.8385 - val_accuracy: 0.5671\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8351 - accuracy: 0.5607 - val_loss: 0.8348 - val_accuracy: 0.5657\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8336 - accuracy: 0.5654 - val_loss: 0.8338 - val_accuracy: 0.5463\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8341 - accuracy: 0.5647 - val_loss: 0.8340 - val_accuracy: 0.5485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c869b83d00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=200,batch_size=2120,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b339a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db144cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4703025 , 0.08593804, 0.4437595 ],\n",
       "       [0.2304483 , 0.51640344, 0.25314823],\n",
       "       [0.5241133 , 0.01414536, 0.46174133],\n",
       "       ...,\n",
       "       [0.45567733, 0.04665841, 0.49766433],\n",
       "       [0.2522662 , 0.3529508 , 0.394783  ],\n",
       "       [0.22374633, 0.5278534 , 0.24840024]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4905ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
