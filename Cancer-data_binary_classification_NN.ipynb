{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006973c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c190452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Cancer-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6116dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8433a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ad23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='diagnosis', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data.diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24ab7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as here we can see this is imbalanced data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6546139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973c30b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1e3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7741891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis\n",
       "0           M\n",
       "1           M\n",
       "2           M\n",
       "3           M\n",
       "4           M\n",
       "..        ...\n",
       "564         M\n",
       "565         M\n",
       "566         M\n",
       "567         M\n",
       "568         B\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e413822",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(\"diagnosis\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c65644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "k=LabelEncoder()\n",
    "y1= k.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ad2a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94d851f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e597617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=to_categorical(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8f22fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis\n",
       "0           M\n",
       "1           M\n",
       "2           M\n",
       "3           M\n",
       "4           M\n",
       "..        ...\n",
       "564         M\n",
       "565         M\n",
       "566         M\n",
       "567         M\n",
       "568         B\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09a2beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y1, test_size = 1/3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e26965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63381060",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c4f219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a4e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab0ca158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da859240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d22af97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb98487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceb34c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5014bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffa0a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,input_dim=30,activation=\"tanh\"))\n",
    "    model.add(Dense(20,activation=\"tanh\"))\n",
    "    model.add(Dense(10,activation=\"tanh\"))\n",
    "    model.add(Dense(2,activation=\"sigmoid\"))\n",
    "    opt=Adam(learning_rate=0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44af7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a566bb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 0.7122 - accuracy: 0.4934 - val_loss: 0.6304 - val_accuracy: 0.6421\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6348 - accuracy: 0.6201 - val_loss: 0.5982 - val_accuracy: 0.6421\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6123 - accuracy: 0.6201 - val_loss: 0.5690 - val_accuracy: 0.6421\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5570 - accuracy: 0.6201 - val_loss: 0.4939 - val_accuracy: 0.8211\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5131 - accuracy: 0.7863 - val_loss: 0.4749 - val_accuracy: 0.8368\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4691 - accuracy: 0.8364 - val_loss: 0.4473 - val_accuracy: 0.8789\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4607 - accuracy: 0.8311 - val_loss: 0.4232 - val_accuracy: 0.8579\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4115 - accuracy: 0.8654 - val_loss: 0.3702 - val_accuracy: 0.8789\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3904 - accuracy: 0.8522 - val_loss: 0.3239 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3467 - accuracy: 0.8839 - val_loss: 0.3929 - val_accuracy: 0.8263\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3515 - accuracy: 0.8470 - val_loss: 0.2885 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3088 - accuracy: 0.8892 - val_loss: 0.3291 - val_accuracy: 0.8895\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3628 - accuracy: 0.8602 - val_loss: 0.2772 - val_accuracy: 0.9158\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2823 - accuracy: 0.8918 - val_loss: 0.3513 - val_accuracy: 0.8263\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3210 - accuracy: 0.8654 - val_loss: 0.2487 - val_accuracy: 0.9263\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3012 - accuracy: 0.9024 - val_loss: 0.2972 - val_accuracy: 0.9053\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3263 - accuracy: 0.8813 - val_loss: 0.3305 - val_accuracy: 0.8421\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3380 - accuracy: 0.8443 - val_loss: 0.3693 - val_accuracy: 0.8263\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3152 - accuracy: 0.8734 - val_loss: 0.3884 - val_accuracy: 0.8947\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4336 - accuracy: 0.8470 - val_loss: 0.2941 - val_accuracy: 0.8947\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3210 - accuracy: 0.8786 - val_loss: 0.3748 - val_accuracy: 0.8684\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3418 - accuracy: 0.8839 - val_loss: 0.2534 - val_accuracy: 0.9105\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2958 - accuracy: 0.8918 - val_loss: 0.2550 - val_accuracy: 0.9263\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2834 - accuracy: 0.9024 - val_loss: 0.2507 - val_accuracy: 0.9316\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2933 - accuracy: 0.9050 - val_loss: 0.2409 - val_accuracy: 0.9368\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2807 - accuracy: 0.9077 - val_loss: 0.3364 - val_accuracy: 0.8842\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3168 - accuracy: 0.8839 - val_loss: 0.2946 - val_accuracy: 0.8842\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2908 - accuracy: 0.8865 - val_loss: 0.3075 - val_accuracy: 0.8632\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.3132 - accuracy: 0.8628 - val_loss: 0.2396 - val_accuracy: 0.9158\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2967 - accuracy: 0.8839 - val_loss: 0.3415 - val_accuracy: 0.8737\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2963 - accuracy: 0.8971 - val_loss: 0.2226 - val_accuracy: 0.9421\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3199 - accuracy: 0.8971 - val_loss: 0.4046 - val_accuracy: 0.8684\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4138 - accuracy: 0.8628 - val_loss: 0.3043 - val_accuracy: 0.9053\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3364 - accuracy: 0.8892 - val_loss: 0.3123 - val_accuracy: 0.9368\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3607 - accuracy: 0.9024 - val_loss: 0.4331 - val_accuracy: 0.8632\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3479 - accuracy: 0.8892 - val_loss: 0.2248 - val_accuracy: 0.9368\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3189 - accuracy: 0.9050 - val_loss: 0.2608 - val_accuracy: 0.9526\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3444 - accuracy: 0.8971 - val_loss: 0.2283 - val_accuracy: 0.9368\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.2904 - accuracy: 0.8892 - val_loss: 0.3158 - val_accuracy: 0.8474\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3147 - accuracy: 0.8338 - val_loss: 0.2478 - val_accuracy: 0.9053\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2752 - accuracy: 0.8681 - val_loss: 0.3041 - val_accuracy: 0.8368\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3364 - accuracy: 0.8206 - val_loss: 0.2567 - val_accuracy: 0.9211\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2815 - accuracy: 0.9024 - val_loss: 0.2814 - val_accuracy: 0.8895\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2745 - accuracy: 0.9050 - val_loss: 0.2758 - val_accuracy: 0.9053\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2762 - accuracy: 0.9077 - val_loss: 0.2543 - val_accuracy: 0.9211\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2724 - accuracy: 0.9103 - val_loss: 0.2473 - val_accuracy: 0.9211\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2671 - accuracy: 0.9077 - val_loss: 0.3112 - val_accuracy: 0.8737\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3152 - accuracy: 0.8575 - val_loss: 0.2589 - val_accuracy: 0.8895\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2722 - accuracy: 0.9024 - val_loss: 0.2309 - val_accuracy: 0.9421\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3011 - accuracy: 0.9077 - val_loss: 0.2354 - val_accuracy: 0.9263\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.2598 - accuracy: 0.9129 - val_loss: 0.2514 - val_accuracy: 0.8789\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2846 - accuracy: 0.8522 - val_loss: 0.2665 - val_accuracy: 0.8526\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2660 - accuracy: 0.8681 - val_loss: 0.2638 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2639 - accuracy: 0.9050 - val_loss: 0.2366 - val_accuracy: 0.9211\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2820 - accuracy: 0.9077 - val_loss: 0.2275 - val_accuracy: 0.9316\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2792 - accuracy: 0.9077 - val_loss: 0.2593 - val_accuracy: 0.9105\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2672 - accuracy: 0.9024 - val_loss: 0.2448 - val_accuracy: 0.9105\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2567 - accuracy: 0.8892 - val_loss: 0.2794 - val_accuracy: 0.8526\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2960 - accuracy: 0.8364 - val_loss: 0.2751 - val_accuracy: 0.8895\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2830 - accuracy: 0.8918 - val_loss: 0.2568 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2576 - accuracy: 0.9182 - val_loss: 0.2061 - val_accuracy: 0.9421\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2878 - accuracy: 0.9077 - val_loss: 0.2218 - val_accuracy: 0.9316\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2670 - accuracy: 0.9103 - val_loss: 0.3191 - val_accuracy: 0.8947\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2815 - accuracy: 0.9129 - val_loss: 0.2303 - val_accuracy: 0.9316\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2761 - accuracy: 0.9103 - val_loss: 0.1913 - val_accuracy: 0.9526\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2824 - accuracy: 0.9024 - val_loss: 0.2158 - val_accuracy: 0.9368\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2482 - accuracy: 0.9156 - val_loss: 0.2582 - val_accuracy: 0.8947\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2473 - accuracy: 0.9156 - val_loss: 0.2166 - val_accuracy: 0.9316\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2445 - accuracy: 0.9103 - val_loss: 0.2456 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2479 - accuracy: 0.9129 - val_loss: 0.2474 - val_accuracy: 0.9158\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2590 - accuracy: 0.9129 - val_loss: 0.2259 - val_accuracy: 0.9263\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2410 - accuracy: 0.9129 - val_loss: 0.2344 - val_accuracy: 0.8947\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2455 - accuracy: 0.9050 - val_loss: 0.2667 - val_accuracy: 0.8526\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2802 - accuracy: 0.8470 - val_loss: 0.2665 - val_accuracy: 0.8579\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2802 - accuracy: 0.8470 - val_loss: 0.2757 - val_accuracy: 0.8368\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2933 - accuracy: 0.8259 - val_loss: 0.2801 - val_accuracy: 0.8211\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2786 - accuracy: 0.8338 - val_loss: 0.2688 - val_accuracy: 0.8632\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2667 - accuracy: 0.8918 - val_loss: 0.2139 - val_accuracy: 0.9368\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2825 - accuracy: 0.9156 - val_loss: 0.2091 - val_accuracy: 0.9421\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3129 - accuracy: 0.9024 - val_loss: 0.2124 - val_accuracy: 0.9421\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2859 - accuracy: 0.9103 - val_loss: 0.2977 - val_accuracy: 0.9316\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3137 - accuracy: 0.9129 - val_loss: 0.2960 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2605 - accuracy: 0.9182 - val_loss: 0.2142 - val_accuracy: 0.9368\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2900 - accuracy: 0.9077 - val_loss: 0.2141 - val_accuracy: 0.9316\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2610 - accuracy: 0.9129 - val_loss: 0.2379 - val_accuracy: 0.8579\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2409 - accuracy: 0.9077 - val_loss: 0.2356 - val_accuracy: 0.9105\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2446 - accuracy: 0.8997 - val_loss: 0.2509 - val_accuracy: 0.9105\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2856 - accuracy: 0.8918 - val_loss: 0.2581 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3013 - accuracy: 0.8760 - val_loss: 0.2240 - val_accuracy: 0.9105\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2501 - accuracy: 0.8945 - val_loss: 0.2442 - val_accuracy: 0.8579\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2432 - accuracy: 0.8707 - val_loss: 0.2383 - val_accuracy: 0.8895\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2400 - accuracy: 0.9103 - val_loss: 0.2202 - val_accuracy: 0.9368\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2729 - accuracy: 0.9156 - val_loss: 0.2123 - val_accuracy: 0.9421\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2599 - accuracy: 0.9077 - val_loss: 0.2865 - val_accuracy: 0.8684\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3240 - accuracy: 0.8311 - val_loss: 0.3887 - val_accuracy: 0.7526\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3821 - accuracy: 0.7573 - val_loss: 0.2917 - val_accuracy: 0.8263\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2891 - accuracy: 0.8285 - val_loss: 0.2392 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2886 - accuracy: 0.8892 - val_loss: 0.2397 - val_accuracy: 0.9158\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2994 - accuracy: 0.9024 - val_loss: 0.2166 - val_accuracy: 0.9316\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2662 - accuracy: 0.9182 - val_loss: 0.3396 - val_accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a12c4b1640>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train1,verbose=1,batch_size=220,epochs=100,validation_data=(x_test,y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0fa14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_yp=model.predict_classes(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f468a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42238b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_train1=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c097234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9535381 , 0.04447412],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9534868 , 0.04452193],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535344 , 0.04447773],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.10420018, 0.88865614],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.8895225 , 0.09352148],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535382 , 0.0444741 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535335 , 0.04447848],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07258207, 0.93323517],\n",
       "       [0.9535382 , 0.0444741 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95191145, 0.04602265],\n",
       "       [0.9515532 , 0.04632583],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.03852767, 0.9652619 ],\n",
       "       [0.70003515, 0.25104162],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.03852767, 0.9652619 ],\n",
       "       [0.81235623, 0.14084691],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.87709916, 0.1014151 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.40490374, 0.45305586],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.90068936, 0.08610141],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.83271027, 0.14796987],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07266629, 0.93316305],\n",
       "       [0.07262108, 0.9331852 ],\n",
       "       [0.7825043 , 0.18656337],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535303 , 0.04448146],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.94924724, 0.04871014],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95353174, 0.04448077],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.62351525, 0.284419  ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.8494168 , 0.11842838],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.6848309 , 0.263483  ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.95353794, 0.0444743 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535284 , 0.04448318],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535382 , 0.0444741 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9517385 , 0.0462999 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535354 , 0.04447693],\n",
       "       [0.7925994 , 0.16300246],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535377 , 0.04447457],\n",
       "       [0.07310176, 0.93256885],\n",
       "       [0.9535383 , 0.0444741 ],\n",
       "       [0.07258251, 0.93323517],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95353246, 0.04447997],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95344234, 0.04457176],\n",
       "       [0.07257947, 0.9332386 ],\n",
       "       [0.275234  , 0.61970997],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257941, 0.93323874],\n",
       "       [0.8724143 , 0.10423523],\n",
       "       [0.9535295 , 0.04448304],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9508467 , 0.04719263],\n",
       "       [0.85001373, 0.11806315],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.95353645, 0.0444757 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07558376, 0.9305947 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535382 , 0.04447404],\n",
       "       [0.07313073, 0.932529  ],\n",
       "       [0.07257995, 0.933238  ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07765016, 0.92869663],\n",
       "       [0.85645413, 0.11411256],\n",
       "       [0.849413  , 0.11843061],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.81461674, 0.13949043],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07670358, 0.9293777 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.11201289, 0.8767749 ],\n",
       "       [0.80298936, 0.1709626 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.953538  , 0.04447433],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447398],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.6498838 , 0.29178274],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.0729585 , 0.93276167],\n",
       "       [0.85360456, 0.11589572],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257989, 0.933238  ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257953, 0.9332385 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.03530914, 0.9688434 ],\n",
       "       [0.9535383 , 0.04447398],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535382 , 0.04447412],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.66650814, 0.27887142],\n",
       "       [0.9535359 , 0.04447621],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.95286214, 0.04510352],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.7922658 , 0.1727618 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535298 , 0.04448274],\n",
       "       [0.95307946, 0.04490101],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.5223133 , 0.37835062],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.2030743 , 0.73129284],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535382 , 0.0444741 ],\n",
       "       [0.74608934, 0.21336788],\n",
       "       [0.84904224, 0.11865744],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535378 , 0.04447457],\n",
       "       [0.9535363 , 0.04447591],\n",
       "       [0.9535097 , 0.0445033 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95353806, 0.04447433],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447404],\n",
       "       [0.953538  , 0.04447436],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.95353633, 0.04447588],\n",
       "       [0.3767196 , 0.48551828],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535132 , 0.04449734],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.09014282, 0.91694367],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535202 , 0.0444909 ],\n",
       "       [0.27779186, 0.6159891 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9510294 , 0.04681563],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.953213  , 0.04477662],\n",
       "       [0.9535154 , 0.04449743],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95351315, 0.04449934],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535381 , 0.04447418],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07270607, 0.93311995],\n",
       "       [0.9535383 , 0.04447398],\n",
       "       [0.18475658, 0.7891356 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535371 , 0.04447505],\n",
       "       [0.95179105, 0.04624519],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.0444741 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95353603, 0.04447615],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95353794, 0.04447436],\n",
       "       [0.9535272 , 0.04448438],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.03852767, 0.9652619 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.27194533, 0.6727383 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535377 , 0.04447463],\n",
       "       [0.03530911, 0.9688433 ],\n",
       "       [0.9429525 , 0.05465272],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.953531  , 0.04448146],\n",
       "       [0.03530905, 0.96884334],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535337 , 0.04447865],\n",
       "       [0.9535378 , 0.04447463],\n",
       "       [0.08983549, 0.9150619 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.95344365, 0.04456204],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.87023765, 0.10558641],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535239 , 0.04448751],\n",
       "       [0.9534827 , 0.0445258 ],\n",
       "       [0.9534975 , 0.04451504],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9526726 , 0.04535615],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95351714, 0.04449537],\n",
       "       [0.9532441 , 0.04477456],\n",
       "       [0.95292914, 0.04504097],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9534266 , 0.0445779 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95238435, 0.04554904],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.95288587, 0.04511037],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.8490342 , 0.1186626 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.0444741 ],\n",
       "       [0.9535382 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447398],\n",
       "       [0.95353806, 0.04447427],\n",
       "       [0.03530914, 0.9688434 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9532014 , 0.0447875 ],\n",
       "       [0.9047774 , 0.08895493],\n",
       "       [0.65390104, 0.28975442],\n",
       "       [0.0725871 , 0.93323183],\n",
       "       [0.08536297, 0.92157817],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.66130227, 0.23399833],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.23196563, 0.73170316],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535328 , 0.04447916],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.65385103, 0.2897988 ],\n",
       "       [0.07257935, 0.93323874],\n",
       "       [0.08287859, 0.9195051 ],\n",
       "       [0.9535383 , 0.04447407],\n",
       "       [0.9535383 , 0.04447407]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c531c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy=np.argmax(y_train1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83a664cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f44b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_train= np.argmax(yp_train1, axis=-1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fcda6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab2cb1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9831effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94bb369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train=confusion_matrix(y_train,yp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "990c752b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[221,  14],\n",
       "       [ 18, 126]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "420f0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=(126+221)/(221+14+18+126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04e8be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9155672823218998"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23045eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall=(126)/(126+18)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86dfdfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision=(126)/(126+14)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59b840e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2599d135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873239436619719"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train,yp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56669c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train,yp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b2a9739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train,yp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9927babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_test1=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4390fbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03105339, 0.9779084 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28623348, 0.6642442 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.2940802 , 0.6550975 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.36653158, 0.574412  ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.02906632, 0.97940314],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28664434, 0.6637631 ],\n",
       "       [0.92680824, 0.07716653],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.02910173, 0.97938234],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.9261665 , 0.0777204 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.29683197, 0.6519097 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054765, 0.9783183 ],\n",
       "       [0.2860847 , 0.66441834],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28609252, 0.6644093 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28607845, 0.6644255 ],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.03056705, 0.9783026 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92658615, 0.07735813],\n",
       "       [0.92680866, 0.07716602],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.03065005, 0.9782355 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28441888, 0.6663222 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.9267626 , 0.07720584],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.2463615 , 0.7108973 ],\n",
       "       [0.9267015 , 0.07725859],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.02906632, 0.97940314],\n",
       "       [0.92680883, 0.07716599],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.286084  , 0.6644193 ],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92678154, 0.07718953],\n",
       "       [0.28609264, 0.66440916],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.3087598 , 0.6382092 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.9268085 , 0.07716623],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92661434, 0.07733384],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.9267081 , 0.07725295],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.9268086 , 0.07716611],\n",
       "       [0.2854253 , 0.66517156],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.49751648, 0.44306126],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.2847396 , 0.6659553 ],\n",
       "       [0.02906632, 0.97940314],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.02906632, 0.97940314],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.36680967, 0.57411456],\n",
       "       [0.2860844 , 0.6644187 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.83599913, 0.15324542],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28608316, 0.6644202 ],\n",
       "       [0.92674595, 0.0772202 ],\n",
       "       [0.2859917 , 0.66452456],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.02906629, 0.97940314],\n",
       "       [0.2860592 , 0.6644475 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054795, 0.9783179 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28601193, 0.6645015 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.03054768, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.0305478 , 0.9783181 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03056979, 0.97830033],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.9268086 , 0.0771662 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.03054759, 0.9783182 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.28608435, 0.66441876],\n",
       "       [0.92680883, 0.0771659 ],\n",
       "       [0.02906632, 0.97940314],\n",
       "       [0.92680883, 0.0771659 ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8ba9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_test= np.argmax(yp_test1, axis=-1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d182faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5b200a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6829d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28b448be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5b2091c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793cf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
